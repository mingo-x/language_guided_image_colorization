# Language-Guided Image Colorization

## Data Preparation & Set-up
### Data sources
* Image: COCO 2017 train/test split
* Language: COCO 2015 captioning challenge
* Segmentation: [COCO-Stuff dataset](https://github.com/nightrome/cocostuff)
* Word embedding: [download]()
* Vocabulary indexing: [download](https://drive.google.com/open?id=1lHcJkbuNgrTU8zWw1DNbJhSMeGBg8n4x)
### Data pre-processing

### Data paths
## Training
## Inference
## Evaluation
### AMT
### Reference Metrics
## Results

## Pretrained Model
Download the pretrained weights for the full method [here](https://drive.google.com/open?id=1LGqmmiUok_Gwhvq0z5DYClOalLigMQQG).

## Acknowledgement
* [COCO-Stuff](https://github.com/nightrome/cocostuff)
* [Colorful Image Colorization](https://github.com/richzhang/colorization)
* [colorization-tf](https://github.com/nilboy/colorization-tf)
* [deeplab-pytorch](https://github.com/kazuto1011/deeplab-pytorch)
* [FiLM: Visual Reasoning with a General Conditioning Layer](https://github.com/ethanjperez/film)
* [Learning to Color from Language](https://github.com/superhans/colorfromlanguage)
* [Image Captions Generation with Spatial and Channel-wise Attention](https://github.com/zjuchenlong/sca-cnn.cvpr17)
